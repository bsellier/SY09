{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83489c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "starbucks = pd.read_csv(\"D:/UTC/SY09/Projet/tests locaux/clean_starbucks.csv\")\n",
    "starbucksX = starbucks.drop(columns=[\"product_name\", \"milk\", \"size\", \"whip\", \"serv_size_m_l\", \"Category\"])\n",
    "#starbucksX = starbucks.drop(columns=[\"product_name\", \"size\", \"Category\"])\n",
    "starbucksZ = starbucks.Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d497659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(z_pred, z_test):\n",
    "    z_comp = pd.DataFrame({\"Prediction\": z_pred, \"Realite\": z_test})\n",
    "    categories = [\"coffee\", \"tea\", \"frappuccino\", \"chocolate\", \"other\"]\n",
    "    res = {}\n",
    "    \n",
    "    for i in categories : # attendu\n",
    "        values = []\n",
    "        for j in categories: # predit\n",
    "            values.append(100 * len(z_comp[ (z_comp[\"Realite\"]==i) & (z_comp[\"Prediction\"]==j)]) / len(z_comp[z_comp[\"Realite\"]==i]))\n",
    "        res[i] = values\n",
    "        \n",
    "    conf = pd.DataFrame(res)\n",
    "    indexes = []\n",
    "    for i in conf.columns:\n",
    "        indexes.append(i + \"_pred\")\n",
    "    conf[\"index\"] = indexes\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78011538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable           chocolate      coffee frappuccino        other         tea\n",
      "index                                                                        \n",
      "chocolate_pred    71.3 ± 8.1   0.1 ± 0.2   0.6 ± 0.6    0.0 ± 0.0   1.0 ± 1.4\n",
      "coffee_pred        0.1 ± 0.6  87.4 ± 2.6   0.9 ± 0.8    0.0 ± 0.0  10.4 ± 3.4\n",
      "frappuccino_pred   0.0 ± 0.0   6.3 ± 1.6  97.4 ± 1.4   10.0 ± 8.6   0.0 ± 0.0\n",
      "other_pred         5.5 ± 3.7   0.0 ± 0.0   0.0 ± 0.0  52.3 ± 15.2   2.0 ± 2.0\n",
      "tea_pred          23.1 ± 7.6   6.3 ± 1.9   1.0 ± 0.9  37.7 ± 14.0  86.6 ± 3.8\n",
      "variable           chocolate      coffee frappuccino        other         tea\n",
      "index                                                                        \n",
      "chocolate_pred    95.0 ± 4.0   0.0 ± 0.0   0.0 ± 0.0    0.0 ± 0.0   0.1 ± 0.4\n",
      "coffee_pred        4.4 ± 3.8  84.8 ± 2.6   1.1 ± 0.9    7.4 ± 9.9   8.3 ± 3.9\n",
      "frappuccino_pred   0.0 ± 0.0   6.1 ± 1.6  98.7 ± 1.0   8.7 ± 10.2   0.1 ± 0.3\n",
      "other_pred         0.6 ± 1.5   1.5 ± 1.1   0.2 ± 0.4  77.0 ± 17.2  15.2 ± 7.9\n",
      "tea_pred           0.0 ± 0.0   7.6 ± 2.4   0.0 ± 0.0    7.0 ± 9.5  76.3 ± 8.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leond\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leond\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leond\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\leond\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable           chocolate      coffee frappuccino        other         tea\n",
      "index                                                                        \n",
      "chocolate_pred    97.1 ± 3.7   0.0 ± 0.1   0.3 ± 0.4    5.1 ± 5.9   0.0 ± 0.0\n",
      "coffee_pred        0.0 ± 0.0  89.5 ± 2.1   6.5 ± 2.0    0.0 ± 0.0  11.2 ± 3.6\n",
      "frappuccino_pred   0.0 ± 0.0   6.1 ± 1.6  92.3 ± 2.3    7.1 ± 9.6   0.0 ± 0.0\n",
      "other_pred         1.4 ± 2.6   0.0 ± 0.1   0.0 ± 0.0  61.9 ± 15.6   1.2 ± 1.2\n",
      "tea_pred           1.6 ± 2.6   4.4 ± 1.6   1.0 ± 1.0  25.9 ± 12.9  87.6 ± 3.8\n"
     ]
    }
   ],
   "source": [
    "def big_confusion_matrix(cls, nb_models) :\n",
    "\n",
    "    matrices = []\n",
    "\n",
    "    # On stocke les matrices de confusion de chaque modèle généré\n",
    "    \n",
    "    for i in range(0,nb_models):\n",
    "\n",
    "        X_train, X_test, z_train, z_test = train_test_split(starbucksX, starbucksZ, test_size=0.33, random_state=i)\n",
    "        cls.fit(X_train, z_train)\n",
    "        z_pred = cls.predict(X_test)\n",
    "\n",
    "        conf = confusion_matrix(z_pred, z_test)\n",
    "        #print(conf)\n",
    "        #print(conf.melt(id_vars=[\"index\"], value_name=i))\n",
    "        matrices.append(conf.melt(id_vars=[\"index\"], value_name=i))\n",
    "\n",
    "    # On construit une matrice qui stocke les pourcentages obtenus dans des colonnes nommées de 0 à nb_models  \n",
    "    \n",
    "    CF = matrices[0]\n",
    "\n",
    "    for i in range(1,len(matrices)):\n",
    "        CF = pd.concat([CF, matrices[i][i]], axis = 1)\n",
    "\n",
    "    # On calcule les moyennes et écarts-types de chaque case de la matrice de confusion\n",
    "    \n",
    "    CF[\"average\"] = CF[range(0, nb_models)].mean(axis=1).round(decimals=1).astype(str)\n",
    "    CF[\"std\"] = CF[range(0, nb_models)].std(axis=1).round(decimals=1).astype(str)\n",
    "    \n",
    "    # On met en forme le résultat puis on pivote la table pour bien avoir la matrice de confusion attendue\n",
    "    \n",
    "    CF[\"value\"] = CF[\"average\"] + \" ± \" + CF[\"std\"]\n",
    "    CF = CF.drop(columns=range(0, nb_models))\n",
    "    CF = CF.drop(columns=[\"average\",\"std\"])\n",
    "    CF = CF.pivot(index='index', columns='variable')['value']\n",
    "    \n",
    "    return CF\n",
    "    \n",
    "nb_models = 100\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "lr = LogisticRegression(max_iter=5000)\n",
    "\n",
    "print(big_confusion_matrix(lda, nb_models))\n",
    "print(big_confusion_matrix(qda, nb_models))\n",
    "print(big_confusion_matrix(lr, nb_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae37ee1",
   "metadata": {},
   "source": [
    "Démarche : on produit 100 modèles de chaque et calcule la moyenne et l'écart-type de chaque case des matrices de confusion. Pour des raisons techniques, on n'utilise pas les modèles issus de la cross-validation\n",
    "\n",
    "\n",
    "LDA : \n",
    "- Chocolats : thés, (autres)\n",
    "- Cafés : (frappuccinos, thés)\n",
    "- Frappuccinos : peu confondus\n",
    "- Autres : thés, frappuccinos\n",
    "- Thés : cafés\n",
    "\n",
    "QDA : \n",
    "- Chocolats : (cafés)\n",
    "- Cafés : (frappuccinos, thés)\n",
    "- Frappuccinos : peu confondus\n",
    "- Autres : un peu plus précis que LDA, thés, frappuccino\n",
    "- Thés : moins précis sur les thés, cafés et autres\n",
    "\n",
    "==> À ce stade, on privilégie les modèles LDA qui sont plus précis sur les thés. On perd en précision sur la catégorie autres ce qui est moins grave.\n",
    "\n",
    "LR : \n",
    "- Chocolats : peu confondus (+26)\n",
    "- Cafés : (frappuccinos, thés), taux un peu meilleurs que LDA (+2)\n",
    "- Frappuccinos : (cafés), moins bon de LDA (-5)\n",
    "- Autres : thés, (frappuccino, chocolat), moins bon que LDA\n",
    "- Thés : cafés, proche de LDA\n",
    "\n",
    "==> On privilégie LR, qui prédit beaucoup mieux les chocolats, ce qui nous coute une faible baisse de précision pour les frappuccinos. Ces modèles ont de plus hauts pourcentages de bonnes prédictions dans toutes les classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149dba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
